# Robora Vision Modules

A small Python library that provides **plug-and-play vision skills** reusable across Robora demos and inside robot â€œbrainsâ€.

---

## âœ¨ Features
- **Object Detection** (YOLOv8 wrapper)  
- **Image Segmentation** (SAM-lite or similar lightweight segmenter)  
- **Marker / Barcode Detection** (ArUco or QR)  
- **Unified Python API** for simple usage  
- **Command-line tools (CLI)** for quick demos  
- **Tiny evaluation script** for COCO-style datasets  

---

## ğŸ“‚ Repository Structure
```
Vision_Modules/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ rvm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py                # unified high-level API
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ types.py          # dataclasses for boxes, masks, markers
â”‚   â”‚   â””â”€â”€ visualize.py      # drawing utilities
â”‚   â”œâ”€â”€ detect/
â”‚   â”‚   â””â”€â”€ yolo.py           # detection wrapper
â”‚   â”œâ”€â”€ segment/
â”‚   â”‚   â””â”€â”€ sam_lite.py       # segmentation wrapper
â”‚   â”œâ”€â”€ markers/
â”‚   â”‚   â””â”€â”€ aruco.py          # marker / QR detection
â”‚   â””â”€â”€ io/
â”‚       â”œâ”€â”€ loader.py         # image, video, webcam loading
â”‚       â””â”€â”€ writer.py         # save JSON + annotated media
â”œâ”€â”€ demos/
â”‚   â”œâ”€â”€ detect_webcam.py
â”‚   â”œâ”€â”€ detect_video.py
â”‚   â”œâ”€â”€ segment_image.py
â”‚   â””â”€â”€ markers_image.py
â”œâ”€â”€ eval/
â”‚   â””â”€â”€ coco_eval.py          # detection metrics + report.html
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api_smoke.py
â”‚   â”œâ”€â”€ test_visualize.py
â”‚   â””â”€â”€ test_coco_eval.py
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ shelf.jpg
â”‚   â””â”€â”€ tags.png
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml            # CI pipeline: run tests on push
```

---

## ğŸš€ Installation

```bash
Updating
```

---

## ğŸ“¦ Requirements
- torch >= 2.2  
- ultralytics >= 8.1  
- opencv-python >= 4.9  
- numpy >= 1.26  
- matplotlib >= 3.8  
- pyzbar >= 0.1.9 (or `opencv-contrib-python` if using ArUco)  
- pycocotools >= 2.0.7  

---

## ğŸ§‘â€ğŸ’» Usage

### Python API
```python
Updating
```

### CLI Commands
```bash
rvm-detect --source path_or_webcam --model yolov8n.pt --out results/
rvm-segment --source images_dir --out results/
rvm-markers --source images_dir --out results/
rvm-eval-coco --images images_dir --ann annotations.json --out reports/
```

---

## ğŸ¥ Demos
- `demos/detect_webcam.py` â†’ run YOLO detection live from webcam  
- `demos/detect_video.py` â†’ detect objects in video, save annotated MP4 + JSON  
- `demos/segment_image.py` â†’ run SAM-lite segmentation on an image  
- `demos/markers_image.py` â†’ detect QR/ArUco markers in image  

---

## ğŸ“Š Evaluation
Run COCO-style evaluation on a small dataset:

```bash
Updating
```

Outputs **precision, recall, and report.html**.

---

## âœ… Tests & CI
- Updating

---

## ğŸ“Œ Roadmap
- Updating  

---

## ğŸ‘¥ Authors
Maintained by **Robora**.  
Contributor: [@ncquy](https://github.com/ncquy), *Updating...* 
